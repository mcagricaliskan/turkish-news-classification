{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# loadijg dataset\n",
    "dataset = json.load(open(\"Dataset/tf-idf-dataset.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset length: 42663\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "classes = dataset[\"ClassNames\"]\n",
    "\n",
    "# extracting X and y from json dataset\n",
    "for data in dataset[\"Dataset\"]:\n",
    "    X.append(data[\"x\"])\n",
    "    y.append(data[\"y\"])\n",
    "\n",
    "print(f\"total dataset length: {len(X)}\")\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# spliting dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29864, 5000)\n",
      "(29864, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1000)              5001000   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 500)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 200)               100200    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 1608      \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,603,308\n",
      "Trainable params: 5,603,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "234/234 [==============================] - 3s 8ms/step - loss: 0.5030 - accuracy: 0.8383 - val_loss: 0.3614 - val_accuracy: 0.8756\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.2130 - accuracy: 0.9251 - val_loss: 0.3932 - val_accuracy: 0.8701\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - 2s 7ms/step - loss: 0.1043 - accuracy: 0.9648 - val_loss: 0.4738 - val_accuracy: 0.8657\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0460 - accuracy: 0.9847 - val_loss: 0.6057 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.6796 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 0.7611 - val_accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9953 - val_loss: 0.7901 - val_accuracy: 0.8668\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0092 - accuracy: 0.9960 - val_loss: 0.8493 - val_accuracy: 0.8644\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9965 - val_loss: 0.8975 - val_accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - 1s 6ms/step - loss: 0.0045 - accuracy: 0.9976 - val_loss: 0.9591 - val_accuracy: 0.8662\n"
     ]
    }
   ],
   "source": [
    "## training ANN with keras\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(5000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(len(classes))) # output layer\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=10, verbose=1)\n",
    "model.save(f\"Models/keras_ann_v1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting y_red for x_test i want to see test set precission, classification_report and confusion_matrix\n",
    "y_pred = model.predict(x_test, batch_size=128)\n",
    "y_pred_1d = y_pred.argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
    "\n",
    "# np.argmax() gets max argument index of y list\n",
    "# example argmax to [0, 0, 1, 0] result will be 2 (class index) \n",
    "test__data_accuracy_score = accuracy_score(np.argmax(y_test), np.argmax(y_pred, axis=1))\n",
    "# print(f\"Accuracy for x_test: {accuracy_score}\")\n",
    "# print(confusion_matrix())\n",
    "# print(f1_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9116120a73e4c85693ba75cec13d1495ad1ecdb600f953e70464207228840cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
